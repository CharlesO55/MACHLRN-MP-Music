{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b96aa8-def6-4ad4-9fb3-e5beac27ee07",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "Explain what it is and why you picked it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087f6bc-f1db-4799-bd68-8ce9266d7277",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "Import matplotlib, csv, numpy, and torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d292c80-f64a-42ac-b739-481a657df300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from neural_network import NeuralNetwork\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca5528-4f64-43b8-8ce0-faa67ad9fd68",
   "metadata": {},
   "source": [
    "### Metric\n",
    "\n",
    "The metric we will be using is the `precision_score`, since we are mostly just interested in how well the model performs in making predictions.\n",
    "\n",
    "Gauging the actual Positive/Negative is not as important as precision is a metric that isolates the performance of positive  predictions created by the model. It focuses more on the ratio of correctly predicted positive instances to the total predicted positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b464d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Score(model, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    \n",
    "    #Retrieve the precision score of test & train via sklearn's precision_score\n",
    "    precision_train = precision_score(model.predict(X_train), y_train, average=None)\n",
    "    precision_test = precision_score(model.predict(X_test), y_test, average=None)\n",
    "    \n",
    "    #Graph the scores using the graph_Score function if verbose is set to TRUE\n",
    "    if verbose:\n",
    "        graph_Scores((precision_train, precision_test))\n",
    "        \n",
    "        print(f\"Train Avg Precision : {precision_train.mean():.4f}\")\n",
    "        print(f\"Test Avg Precision : {precision_test.mean():.4f}\")\n",
    "        \n",
    "    return precision_train, precision_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d47c0",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will be using the dataset titled: `Dataset 6 - Music Dataset` for our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0170ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataLoader('Dataset 6 - Music Dataset/music.csv', True, True).df['standardize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5d42b",
   "metadata": {},
   "source": [
    "### Music Dataset\n",
    "We will use the music dataset as out dataset. Each instance represents distinct features with the song:\n",
    "- `Artist Name` - Name of artist\n",
    "- `Track Name` - Name of song\n",
    "- `Popularity` - a value between 0 and 100, with 100 being the most popular\n",
    "- `danceability` - describes how suitable a track is for dancing\n",
    "- `energy` - perceptual measure of intensity and activity\n",
    "- `key` - The key the track is in\n",
    "- `loudness` - The overall loudness of a track in decibels (dB)\n",
    "- `mode` - indicates the modality (major or minor) of a track\n",
    "- `speechiness` - detects the presence of spoken words in a track\n",
    "- `acousticness` - A measure for whether the track is acoustic\n",
    "- `instrumentalness` - Predicts whether a track contains no vocals\n",
    "- `liveness` - Detects the presence of an audience in the recording\n",
    "- `valence` - Describes the musical positiveness conveyed by a track\n",
    "- `tempo` - The overall estimated tempo of a track in beats per minute (BPM)\n",
    "- `duration_inmin/ms` - Duration in ms\n",
    "- `time_signature` - Specifies how many beats are in each bar (or measure)\n",
    "\n",
    "The songs can be divided into 11 different genres.\n",
    "- `Pop` - class 0\n",
    "- `Hip-hop` - class 1\n",
    "- `Blues` - class 2\n",
    "- `Indian-pop` - class 3\n",
    "- `Country` - class 4\n",
    "- `Rap` - class 5\n",
    "- `Rock` - class 6\n",
    "- `Ambient` - class 7\n",
    "- `Metal` - class 8\n",
    "- `R&B` - class 9\n",
    "- `Indie` - class 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f9dd0",
   "metadata": {},
   "source": [
    "### Loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a7e008",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m         X_music \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([X_music, features])\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# Append the class label\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m         y_music \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(y_music, np\u001b[38;5;241m.\u001b[39marray([classes[row[\u001b[38;5;241m16\u001b[39m]]]))  \u001b[38;5;66;03m# Class column\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Reshape y_music to have the shape (N, 1)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m y_music \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(y_music, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '5'"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    'Pop': 0,\n",
    "    'Hip-hop': 1,\n",
    "    'Blues': 2,\n",
    "    'Indian-pop': 3,\n",
    "    'Country': 4,\n",
    "    'Rap': 5,\n",
    "    'Rock': 6,\n",
    "    'Ambient': 7,\n",
    "    'Metal': 8,\n",
    "    'R&B': 9,\n",
    "    'Indie': 10,\n",
    "}\n",
    "\n",
    "with open('Dataset 6 - Music Dataset/music.csv', 'r') as csv_file:\n",
    "    raw_data = csv.reader(csv_file)\n",
    "    X_music = np.empty((0, 13), float)  # 13 numeric feature columns\n",
    "    y_music = np.empty((0, 1), int)\n",
    "    \n",
    "    next(raw_data)  # Skip the header row\n",
    "    \n",
    "    for row in raw_data:\n",
    "        # Convert the relevant columns to float and add to X_music\n",
    "        features = np.array([float(row[2]),  # Popularity\n",
    "                             float(row[3]),  # danceability\n",
    "                             float(row[4]),  # energy\n",
    "                             float(row[5]),  # key\n",
    "                             float(row[6]),  # loudness\n",
    "                             float(row[7]),  # mode\n",
    "                             float(row[8]),  # speechiness\n",
    "                             float(row[9]),  # acousticness\n",
    "                             float(row[11]), # liveness\n",
    "                             float(row[12]), # valence\n",
    "                             float(row[13]), # tempo\n",
    "                             float(row[14]), # duration_inmin/ms\n",
    "                             float(row[15])  # time_signature\n",
    "                            ])\n",
    "        X_music = np.vstack([X_music, features])\n",
    "        \n",
    "        # Append the class label\n",
    "        y_music = np.append(y_music, np.array([classes[row[16]]]))  # Class column\n",
    "    \n",
    "# Reshape y_music to have the shape (N, 1)\n",
    "y_music = np.expand_dims(y_music, 1)\n",
    "\n",
    "print('Training data shape:', X_music.shape)\n",
    "print('Ground truth values shape:', y_music.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06365b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_music_0 = X_music[y_music == 0]\n",
    "X_music_1 = X_music[y_music == 1]\n",
    "X_music_2 = X_music[y_music == 2]\n",
    "X_music_3 = X_music[y_music == 3]\n",
    "X_music_4 = X_music[y_music == 4]\n",
    "X_music_5 = X_music[y_music == 5]\n",
    "X_music_6 = X_music[y_music == 6]\n",
    "X_music_7 = X_music[y_music == 7]\n",
    "X_music_8 = X_music[y_music == 8]\n",
    "X_music_9 = X_music[y_music == 9]\n",
    "X_music_10 = X_music[y_music == 10]\n",
    "\n",
    "print('Number of class 0:', len(X_music_0))\n",
    "print('Number of class 1:', len(X_music_1))\n",
    "print('Number of class 2:', len(X_music_2))\n",
    "print('Number of class 3:', len(X_music_3))\n",
    "print('Number of class 4:', len(X_music_4))\n",
    "print('Number of class 5:', len(X_music_5))\n",
    "print('Number of class 6:', len(X_music_6))\n",
    "print('Number of class 7:', len(X_music_7))\n",
    "print('Number of class 8:', len(X_music_8))\n",
    "print('Number of class 9:', len(X_music_9))\n",
    "print('Number of class 10:', len(X_music_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61259b8",
   "metadata": {},
   "source": [
    "Divide the dataset into the train and test set. The test set will contain X instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6ae268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_music_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Select 10 `class 0` instances\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m selected_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(X_music_0)),\n\u001b[0;32m      5\u001b[0m                               size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      6\u001b[0m                               replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Select 10 `class 1` instances\u001b[39;00m\n\u001b[0;32m      9\u001b[0m selected_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(X_music_1)),\n\u001b[0;32m     10\u001b[0m                               size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     11\u001b[0m                               replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_music_0' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Select 10 `class 0` instances\n",
    "selected_0 = np.random.choice(np.arange(len(X_music_0)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 1` instances\n",
    "selected_1 = np.random.choice(np.arange(len(X_music_1)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_2 = np.random.choice(np.arange(len(X_music_2)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "# Select 10 `class 0` instances\n",
    "selected_3 = np.random.choice(np.arange(len(X_music_3)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 1` instances\n",
    "selected_4 = np.random.choice(np.arange(len(X_music_4)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_5 = np.random.choice(np.arange(len(X_music_5)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "# Select 10 `class 0` instances\n",
    "selected_6 = np.random.choice(np.arange(len(X_music_6)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 1` instances\n",
    "selected_7 = np.random.choice(np.arange(len(X_music_7)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_8 = np.random.choice(np.arange(len(X_music_8)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_9 = np.random.choice(np.arange(len(X_music_9)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_10 = np.random.choice(np.arange(len(X_music_10)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Form the test set\n",
    "X_test = np.concatenate((X_iris_0[selected_0],\n",
    "                         X_iris_1[selected_1],\n",
    "                         X_iris_1[selected_2],\n",
    "                         X_iris_1[selected_2],\n",
    "                         X_iris_1[selected_3],\n",
    "                         X_iris_1[selected_4],\n",
    "                         X_iris_1[selected_5],\n",
    "                         X_iris_1[selected_6],\n",
    "                         X_iris_1[selected_7],\n",
    "                         X_iris_1[selected_8],\n",
    "                         X_iris_1[selected_9],\n",
    "                         X_iris_2[selected_10]))\n",
    "y_test = np.concatenate((np.array([0 for _ in range(10)]),\n",
    "                         np.array([1 for _ in range(10)]),\n",
    "                         np.array([2 for _ in range(10)]),\n",
    "                         np.array([3 for _ in range(10)]),\n",
    "                         np.array([4 for _ in range(10)]),\n",
    "                         np.array([5 for _ in range(10)]),\n",
    "                         np.array([6 for _ in range(10)]),\n",
    "                         np.array([7 for _ in range(10)]),\n",
    "                         np.array([8 for _ in range(10)]),\n",
    "                         np.array([9 for _ in range(10)]),\n",
    "                         np.array([10 for _ in range(10)])))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04c2f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_music_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mdelete(X_music_0, selected_0, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      2\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_1, selected_1, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      3\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_2, selected_2, \u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m      4\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_3, selected_3, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      5\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_4, selected_4, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      6\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_5, selected_5, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      7\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_6, selected_6, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      8\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_7, selected_7, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      9\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_8, selected_8, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     10\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_9, selected_9, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     11\u001b[0m                           np\u001b[38;5;241m.\u001b[39mdelete(X_music_10, selected_10, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m)]),\n\u001b[0;32m     13\u001b[0m                           np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m)]),\n\u001b[0;32m     14\u001b[0m                           np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m)]),\n\u001b[0;32m     15\u001b[0m                           np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m)])))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_music_0' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((np.delete(X_music_0, selected_0, 0),\n",
    "                          np.delete(X_music_1, selected_1, 0),\n",
    "                          np.delete(X_music_2, selected_2, 0)),\n",
    "                          np.delete(X_music_3, selected_3, 0),\n",
    "                          np.delete(X_music_4, selected_4, 0),\n",
    "                          np.delete(X_music_5, selected_5, 0),\n",
    "                          np.delete(X_music_6, selected_6, 0),\n",
    "                          np.delete(X_music_7, selected_7, 0),\n",
    "                          np.delete(X_music_8, selected_8, 0),\n",
    "                          np.delete(X_music_9, selected_9, 0),\n",
    "                          np.delete(X_music_10, selected_10, 0))\n",
    "y_train = np.concatenate((np.array([0 for _ in range(40)]),\n",
    "                          np.array([1 for _ in range(40)]),\n",
    "                          np.array([2 for _ in range(40)]),\n",
    "                          np.array([3 for _ in range(40)]),\n",
    "                          np.array([4 for _ in range(40)]),\n",
    "                          np.array([5 for _ in range(40)]),\n",
    "                          np.array([6 for _ in range(40)]),\n",
    "                          np.array([7 for _ in range(40)]),\n",
    "                          np.array([8 for _ in range(40)]),\n",
    "                          np.array([9 for _ in range(40)]),\n",
    "                          np.array([10 for _ in range(40)])))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00591f",
   "metadata": {},
   "source": [
    "Convert the np.ndarray arrays to torch.Tensor. We use torch.Tensor in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e8631",
   "metadata": {},
   "source": [
    "## Setting up the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(13, 11, list_hidden=(20, 10))\n",
    "network.create_network()\n",
    "network.init_weights()\n",
    "network.forward(X_train, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe755dc",
   "metadata": {},
   "source": [
    "Well use Adam as the optimizer with the following parameters:\n",
    "- `params` - the parameters of the network\n",
    "- `lr` = 0.001\n",
    "\n",
    "Then instantiated a nn.CrossEntropyLoss() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655525e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), 0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4007d",
   "metadata": {},
   "source": [
    "### Randomizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ec6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "random_indices = np.random.randint(X_train.shape[0], size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5338d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,probalities = network.forward(X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75337661",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = torch.Tensor(y_train[random_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24636b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(scores, target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf438db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), 0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = torch.sum(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = num_correct/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0393ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 400\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    X_batch, y_batch = data_loader.get_batch(mode='train')\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scores, probabilities = network.forward(X)\n",
    "\n",
    "        loss = criterion(scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe72fd-9140-4ec7-ac1e-678eb4cda33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ver of the dataframe you want to use\n",
    "# df = DataLoader('Dataset 6 - Music Dataset/music.csv', True, True).df['raw']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
