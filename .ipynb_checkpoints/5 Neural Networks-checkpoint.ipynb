{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b96aa8-def6-4ad4-9fb3-e5beac27ee07",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "The last model we have chosen was Neural Networks\n",
    "\n",
    "The reason why we used this model is because since the data set is composed of several features, this model can handle complex relationships between the different features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087f6bc-f1db-4799-bd68-8ce9266d7277",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "Import matplotlib, csv, numpy, and torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d292c80-f64a-42ac-b739-481a657df300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from neural_network import NeuralNetwork\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca5528-4f64-43b8-8ce0-faa67ad9fd68",
   "metadata": {},
   "source": [
    "### Metric\n",
    "\n",
    "The metric we will be using is the `precision_score`, since we are mostly just interested in how well the model performs in making predictions.\n",
    "\n",
    "Gauging the actual Positive/Negative is not as important as precision is a metric that isolates the performance of positive  predictions created by the model. It focuses more on the ratio of correctly predicted positive instances to the total predicted positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Score(model, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    \n",
    "    #Retrieve the precision score of test & train via sklearn's precision_score\n",
    "    precision_train = precision_score(model.predict(X_train), y_train, average=None, zero_division = 1)\n",
    "    precision_test = precision_score(model.predict(X_test), y_test, average=None, zero_division = 1)\n",
    "    \n",
    "    #Graph the scores using the graph_Score function if verbose is set to TRUE\n",
    "    if verbose:\n",
    "        graph_Scores((precision_train, precision_test))\n",
    "        \n",
    "        print(f\"Train Avg Precision : {precision_train.mean():.4f}\")\n",
    "        print(f\"Test Avg Precision : {precision_test.mean():.4f}\")\n",
    "        \n",
    "    return precision_train, precision_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8955a7",
   "metadata": {},
   "source": [
    "### Graphing & plots\n",
    "To visualize how our data looks like, we will use matplotlib, for bar and point graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_Scores(scores, title='', ranges = None):\n",
    "    #Determines the width of each bar in the graph\n",
    "    width = 0.35\n",
    "\n",
    "    #X-axis positions for the training and test scores\n",
    "    br1 = range(len(scores[0])) if ranges is None else ranges\n",
    "    br2 = [x + width for x in br1] \n",
    "\n",
    "    #Create a histogram to visualize the precision scores for the model\n",
    "    plt.bar(br1, scores[0], width=width, edgecolor='black', label='Train Score')\n",
    "    plt.bar(br2, scores[1], width=width, edgecolor='black', label='Test Score')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Precision Score')\n",
    "    plt.xlabel('Class / Genre')\n",
    "\n",
    "    #Show integers in the x axis accordingly\n",
    "    plt.xticks(np.arange(0, 11, 1))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5867334",
   "metadata": {},
   "source": [
    "## Feature Set up & Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bc5ef",
   "metadata": {},
   "source": [
    "### Music Dataset\n",
    "We will use the music dataset as out dataset. Each instance represents distinct features with the song:\n",
    "- `Artist Name`       - Name of artist\n",
    "- `Track Name`        - Name of song\n",
    "- `Popularity`        - a value between 0 and 100, with 100 being the most popular\n",
    "- `danceability`      - describes how suitable a track is for dancing\n",
    "- `energy`            - perceptual measure of intensity and activity\n",
    "- `key`               - The key the track is in\n",
    "- `loudness`          - The overall loudness of a track in decibels (dB)\n",
    "- `mode`              - indicates the modality (major or minor) of a track\n",
    "- `speechiness`       - detects the presence of spoken words in a track\n",
    "- `acousticness`      - A measure for whether the track is acoustic\n",
    "- `instrumentalness`  - Predicts whether a track contains no vocals\n",
    "- `liveness`          - Detects the presence of an audience in the recording\n",
    "- `valence`           - Describes the musical positiveness conveyed by a track\n",
    "- `tempo`             - The overall estimated tempo of a track in beats per minute (BPM)\n",
    "- `duration_inmin/ms` - Duration in ms\n",
    "- `time_signature`    - Specifies how many beats are in each bar (or measure)\n",
    "\n",
    "The songs can be divided into 11 different genres. Upon searching the different songs of the same classes in Google, I as able to determine the 11 classes.\n",
    "- `Pop`        - class 0\n",
    "- `Hip-hop`    - class 1\n",
    "- `Blues`      - class 2\n",
    "- `Indian-pop` - class 3\n",
    "- `Country`    - class 4\n",
    "- `Rap`        - class 5\n",
    "- `Rock`       - class 6\n",
    "- `Ambient`    - class 7\n",
    "- `Metal`      - class 8\n",
    "- `R&B`        - class 9\n",
    "- `Indie`      - class 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e55c1",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d784e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataLoader('Dataset 6 - Music Dataset/music.csv', True, True).df['raw']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b30d9",
   "metadata": {},
   "source": [
    "We will make the results reproducible by assigning the `random_state` with a random arbitrary value of **42**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ac243",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbca50",
   "metadata": {},
   "source": [
    "# 5.0 Setup the features and splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0135090",
   "metadata": {},
   "source": [
    "### Getting batches\n",
    "This would be used when creating batches whenever we train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, y, batch_size, mode='train'):\n",
    "    assert mode in ['train', 'test'], \"Mode must be 'train' or 'test'.\"\n",
    "    \n",
    "    indices = np.arange(X.shape[0])\n",
    "    \n",
    "    if mode == 'train':\n",
    "        indices = np.random.permutation(indices)  # Use permutation instead of shuffle to avoid a None assignment\n",
    "    \n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    \n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        batch_indices = indices[i:i + batch_size]\n",
    "        X_batch = X[batch_indices]\n",
    "        y_batch = y[batch_indices]\n",
    "        \n",
    "        X_batches.append(X_batch)\n",
    "        y_batches.append(y_batch)\n",
    "    \n",
    "    return X_batches, y_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Class')\n",
    "y = df['Class']\n",
    "\n",
    "print(f'X [{X.shape}] : {X.columns}')\n",
    "print(f'y [{y.shape}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7285fff",
   "metadata": {},
   "source": [
    "### Perform train test split\n",
    "Set `test_size` to 0.2 and `stratify` to y to ensure proportional sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd996b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)\n",
    "\n",
    "print(f'X_train {X_train.shape}')\n",
    "print(f'y_train {y_train.shape}')\n",
    "print(f'X_test {X_test.shape}')\n",
    "print(f'y_test {y_test.shape}')\n",
    "\n",
    "plt.hist(y_train, label='Train')\n",
    "plt.hist(y_test, label='Test')\n",
    "plt.ylabel('Samples Taken')\n",
    "plt.xlabel('Class / Genre')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52df5ca",
   "metadata": {},
   "source": [
    "Convert the DataFrame arrays to torch.Tensor. We use torch.Tensor in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to NumPy array\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Convert NumPy array into torch.Tensor array\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ed87f",
   "metadata": {},
   "source": [
    "# 3.1 Neural Network using ReLU\n",
    "\n",
    "Instantiation of the Neural Network with the following parameters:\n",
    "- `Input` - 13\n",
    "- `Output` - 11\n",
    "- `Hidden layers` - 2\n",
    "- `list_hidden` - (50, 100)\n",
    "- `activation` - relu\n",
    "- `weight initialization` - default\n",
    "- `Verbose` - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_network = NeuralNetwork(13, 11, list_hidden=(50, 100), activation='relu')\n",
    "relu_network.create_network()\n",
    "relu_network.init_weights()\n",
    "relu_network.forward(X_train, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc9e4",
   "metadata": {},
   "source": [
    "### Getting the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d66491",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "random_indices = np.random.randint(X_train.shape[0], \n",
    "                                   size=10)\n",
    "\n",
    "relu_scores, probabilities = relu_network.forward(X_train[random_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179779f4",
   "metadata": {},
   "source": [
    "Well use Adam as the optimizer with the following parameters:\n",
    "- `params` - the parameters of the network\n",
    "- `lr` = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(relu_network.parameters(), 0.001)\n",
    "target_classes = torch.Tensor(y_train[random_indices]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11699799",
   "metadata": {},
   "source": [
    "Then instantiated a nn.CrossEntropyLoss() object to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(relu_scores, target_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d5eff",
   "metadata": {},
   "source": [
    "Then we update the gradients and weights of the nerwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Using Backwards Propagation get the gradients\n",
    "loss.backward()\n",
    "\n",
    "# Update the weights\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86980079",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 300\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "total_correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    # Seperate training set into batches\n",
    "    X_batch, y_batch = get_batch(X_train, y_train, 128, mode='train')\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        relu_scores, probabilities = relu_network.forward(X)\n",
    "        \n",
    "        loss = criterion(relu_scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "        \n",
    "        # Get predicted class indices\n",
    "        _, predicted_classes = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Calculate the number of correct predictions\n",
    "        total_correct_predictions += (predicted_classes == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00000005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6acf5",
   "metadata": {},
   "source": [
    "Visualizing the lost per training epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(len(losses))]\n",
    "y_values = losses\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for each training epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158626c8",
   "metadata": {},
   "source": [
    "### Accuracy of the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a81e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_training_accuracy = total_correct_predictions / total_samples\n",
    "relu_training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885a23c",
   "metadata": {},
   "source": [
    "### Trying out the trained network on the test data\n",
    "Setting it to eval mode first to avoid updating the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61065c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299c9d4",
   "metadata": {},
   "source": [
    "Then perform forwad propagation on the test data and get the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d49c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_scores,probabilities = relu_network.forward(X_test);\n",
    "predictions = relu_network.predict(probabilities)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995a81c",
   "metadata": {},
   "source": [
    "Get the accuracy of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy: \", relu_accuracy)\n",
    "print(\"Test Accuracy: \", relu_training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93b915",
   "metadata": {},
   "source": [
    "Get the precision of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = get_Score(relu_network, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebbb11e",
   "metadata": {},
   "source": [
    "# 3.2 ReLU vs. ELU\n",
    "We do the same steps as the previous network but we change the activation function to `ELU` and then compare which is better. \n",
    "\n",
    "Instantiation of the Neural Network with the following parameters:\n",
    "- `Input` - 13\n",
    "- `Output` - 11\n",
    "- `Hidden layers` - 2\n",
    "- `list_hidden` - (50, 100)\n",
    "- `activation` - ELU\n",
    "- `weight initialization` - default\n",
    "- `Verbose` - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_network = NeuralNetwork(13, 11, list_hidden=(50, 100), activation='elu')\n",
    "elu_network.create_network()\n",
    "elu_network.init_weights()\n",
    "elu_network.forward(X_train, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "random_indices = np.random.randint(X_train.shape[0], \n",
    "                                   size=10)\n",
    "\n",
    "elu_scores, probabilities = elu_network.forward(X_train[random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(elu_network.parameters(), 0.001)\n",
    "target_classes = torch.Tensor(y_train[random_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95802dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(elu_scores, target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 300\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "total_correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    # Seperate training set into batches\n",
    "    X_batch, y_batch = get_batch(X_train, y_train, 128, mode='train')\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        elu_scores, probabilities = elu_network.forward(X)\n",
    "        \n",
    "        loss = criterion(elu_scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "        \n",
    "        # Get predicted class indices\n",
    "        _, predicted_classes = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Calculate the number of correct predictions\n",
    "        total_correct_predictions += (predicted_classes == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00000005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1eb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(len(losses))]\n",
    "y_values = losses\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for each training epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb679222",
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_training_accuracy = total_correct_predictions / total_samples\n",
    "elu_training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52baf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9aa29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_scores,probabilities = elu_network.forward(X_test)\n",
    "elu_predictions = elu_network.predict(probabilities)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d194bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_accuracy = accuracy_score(y_test,elu_predictions)\n",
    "print(\"Accuracy: \", elu_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = get_Score(elu_network, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4a6aa",
   "metadata": {},
   "source": [
    "### Comparison for ReLU and ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8e56f",
   "metadata": {},
   "source": [
    "Here we can see that the accuracy of the network got worse by changing the activation fuction from `ReLU` to `ELU`. Because of this we will continue with ReLU as our activation function.\n",
    "\n",
    "From 52.08% to 51.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy ReLU: \", relu_accuracy)\n",
    "print(\"Accuracy ELU: \", elu_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1dd54",
   "metadata": {},
   "source": [
    "# 3.3 Neural Network using ReLU with Weight Initialization\n",
    "To see if the loss has really reached the lowest value for convergence, we tested if weight initialization would be able to bring it lower. Since ELU had a better accuracy compared to ReLU, we will using it for this section. \n",
    "\n",
    "Instantiation of the Neural Network with the following parameters:\n",
    "- `Input` - 13\n",
    "- `Output` - 11\n",
    "- `Hidden layers` - 2\n",
    "- `list_hidden` - (50, 100)\n",
    "- `activation` - ReLU\n",
    "- `weight initialization` - xavier\n",
    "- `Verbose` - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_network = NeuralNetwork(13, 11, list_hidden=(50, 100), activation='relu', init_method='xavier')\n",
    "xavier_network.create_network()\n",
    "xavier_network.init_weights()\n",
    "xavier_network.forward(X_train, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "random_indices = np.random.randint(X_train.shape[0], \n",
    "                                   size=10)\n",
    "\n",
    "xavier_scores, probabilities = xavier_network.forward(X_train[random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d26920",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(xavier_network.parameters(), 0.001)\n",
    "target_classes = torch.Tensor(y_train[random_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa732e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(xavier_scores, target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 300\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "total_correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    # Seperate training set into batches\n",
    "    X_batch, y_batch = get_batch(X_train, y_train, 128, mode='train')\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xavier_scores, probabilities = xavier_network.forward(X)\n",
    "        \n",
    "        loss = criterion(xavier_scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "        \n",
    "        # Get predicted class indices\n",
    "        _, predicted_classes = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Calculate the number of correct predictions\n",
    "        total_correct_predictions += (predicted_classes == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00000005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15658620",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(len(losses))]\n",
    "y_values = losses\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for each training epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_training_accuracy = total_correct_predictions / total_samples\n",
    "xavier_training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_scores,probabilities = xavier_network.forward(X_test);\n",
    "xavier_predictions = xavier_network.predict(probabilities)\n",
    "print(\"Predictions: \", xavier_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d3e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xavier_accuracy = accuracy_score(y_test,xavier_predictions)\n",
    "print(\"Accuracy: \", xavier_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd487acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision = get_Score(xavier_network, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafcdcea",
   "metadata": {},
   "source": [
    "### Comparison for ReLU,  ELU, and Xavier + ReLU \n",
    "Here we can see that by adding weight initialization the accuracy of the predictions got worse compared to having a default weight initialization. Because of this we will use the default weigh initialization values which are mean=0.0 and std=0.01.\n",
    "\n",
    "From 52.08% to 51.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ReLU Accuracy: ', relu_accuracy)\n",
    "print('ELU Accuracy: ', elu_accuracy)\n",
    "print('Xavier + ReLU Accuracy: ', xavier_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dadec6",
   "metadata": {},
   "source": [
    "### Additional\n",
    "When experimenting with another weight initialization technique, to be specific `Kaiming` initialization. The accuracy was 00.91% lower than when we used `Xavier` initialization. \n",
    "\n",
    "For reference this was the computed values for both Xavier and Kaiming initialization.\n",
    "\n",
    "`Xavier`: 0.5183333333333333\n",
    "\n",
    "`Kaiming`: 0.5091666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ddde4",
   "metadata": {},
   "source": [
    "# 3.4 Neural Network with additional tweaking\n",
    "\n",
    "**Changes:**\n",
    "Here we adjusted certain parts to try to increase the accuracy of the ReLU network. \n",
    "This was done by adjusting the following:\n",
    "- `epochs during training` - from 300 -> 500\n",
    "- `batch sizes` - from 128 -> 64\n",
    "\n",
    "The reason why we chose 500 epochs is because when testing different values for the epochs, any value above 500 tends to have either the same or similar results to 500 epochs. With the diminishing returns in mind, we used 500 epochs since that was the value where the outputs stop having significant changes.  \n",
    "\n",
    "As for the reason why we decreased the batch sizes, this is because by decreasing the batch sizes we can have a more stable and more generalizable updates. \n",
    "\n",
    "Instantiation of the Neural Network with the following parameters:\n",
    "- `Input` - 13\n",
    "- `Output` - 11\n",
    "- `Hidden layers` - 5\n",
    "- `list_hidden` - (50, 100)\n",
    "- `activation` - relu\n",
    "- `weight initialization` - default\n",
    "- `Verbose` - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9481c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(13, 11, list_hidden=(50, 100), activation='relu')\n",
    "network.create_network()\n",
    "network.init_weights()\n",
    "network.forward(X_train, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ca087",
   "metadata": {},
   "source": [
    "**Note:** When changing the number of hidden layers, we noticed that the network also performed worse. With that in mind, we opted to keep it at two hidden layers with (50, 100) as its values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aab349",
   "metadata": {},
   "source": [
    "### Getting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e399f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "random_indices = np.random.randint(X_train.shape[0], \n",
    "                                   size=10)\n",
    "\n",
    "scores, probabilities = network.forward(X_train[random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), 0.001)\n",
    "target_classes = torch.Tensor(y_train[random_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(scores, target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8930cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Using Backwards Propagation get the gradients\n",
    "loss.backward()\n",
    "\n",
    "# Update the weights\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017c2a3",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 300\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "total_correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    # Seperate training set into batches\n",
    "    X_batch, y_batch = get_batch(X_train, y_train, 128, mode='train')\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scores, probabilities = network.forward(X)\n",
    "        \n",
    "        loss = criterion(relu_scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "        \n",
    "        # Get predicted class indices\n",
    "        _, predicted_classes = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Calculate the number of correct predictions\n",
    "        total_correct_predictions += (predicted_classes == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00000005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09722f",
   "metadata": {},
   "source": [
    "Visualizing the lost per training epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27147c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(len(losses))]\n",
    "y_values = losses\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for each training epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e581cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = total_correct_predictions / total_samples\n",
    "training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e97e5",
   "metadata": {},
   "source": [
    "### Trying out the trained network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98117909",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63349188",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,probabilities = network.forward(X_test);\n",
    "predictions = network.predict(probabilities)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d652827",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy: \", relu_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = get_Score(network, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ca25d",
   "metadata": {},
   "source": [
    "### Previous Network vs Tweaked Network\n",
    "Here we can see that by adding another layer to the hidden layers the accuracy of the predictions got slightly better compared to having only two hidden layers.\n",
    "\n",
    "From 52.08% to 52.19%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81491b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ReLU Accuracy: ', relu_accuracy)\n",
    "print('ReLU + Adjustments: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b01f3d",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In creating these models, we learned the following...\n",
    "<ol>\n",
    "    <li>Neural Networks have many ways to improve the performance of the network. This includes optimization techniques, batch size adjustments, and weight initialization.\n",
    "    <li>To improve the accuracy, extensive testing is needed to find the right values for its hyperparameters.\n",
    "    <li>Neural Networks can improve by adjusting the number of hidden layers.\n",
    "    <li>The activation function plays a major role in the performance of the network. So finding the right one will greatly improve the networks performance.\n",
    "    <li>Although there are improvements when adjusting the hyperparameters and optimization techniques of the network there is not much change in the accuracy of the model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eba2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ReLU + Adjustments Training: {training_accuracy:.4f}')\n",
    "print(f'ReLU + Adjustments Test: {accuracy:.4f}')\n",
    "\n",
    "print(f'ReLU Training: {relu_training_accuracy:.4f}')\n",
    "print(f'ReLU Test: {relu_accuracy:.4f}')\n",
    "\n",
    "print(f'Xavier + ReLU Training: {xavier_training_accuracy:.4f}')\n",
    "print(f'Xavier + ReLU Test: {xavier_accuracy:.4f}')\n",
    "\n",
    "print(f'ELU Training: {elu_training_accuracy:.4f}')\n",
    "print(f'ELU Test: {elu_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66864005",
   "metadata": {},
   "source": [
    "**Best Scores:**\n",
    "\n",
    "Train Accuracy: ReLU + Adjustments ~52.50%\n",
    "\n",
    "Test Accuracy: ReLU + Adjustments ~52.08%\n",
    "\n",
    "**Worst Scores:**\n",
    "\n",
    "Train Accuracy: ELU ~51.83%\n",
    "\n",
    "Test Accuracy: ELU ~51.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe72fd-9140-4ec7-ac1e-678eb4cda33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ver of the dataframe you want to use\n",
    "# df = DataLoader('Dataset 6 - Music Dataset/music.csv', True, True).df['raw']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
