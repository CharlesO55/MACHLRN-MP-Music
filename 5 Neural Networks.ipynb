{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b96aa8-def6-4ad4-9fb3-e5beac27ee07",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "The last model we have chosen was Neural Networks\n",
    "\n",
    "The reason why we used this model is because since the data set is composed of several features, this model can handle complex relationships between the different features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087f6bc-f1db-4799-bd68-8ce9266d7277",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "Import matplotlib, csv, numpy, and torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d292c80-f64a-42ac-b739-481a657df300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from neural_network import NeuralNetwork\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca5528-4f64-43b8-8ce0-faa67ad9fd68",
   "metadata": {},
   "source": [
    "### Metric\n",
    "\n",
    "The metric we will be using is the `precision_score`, since we are mostly just interested in how well the model performs in making predictions.\n",
    "\n",
    "Gauging the actual Positive/Negative is not as important as precision is a metric that isolates the performance of positive  predictions created by the model. It focuses more on the ratio of correctly predicted positive instances to the total predicted positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d1b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Score(model, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    \n",
    "    #Retrieve the precision score of test & train via sklearn's precision_score\n",
    "    precision_train = precision_score(model.predict(X_train), y_train, average=None)\n",
    "    precision_test = precision_score(model.predict(X_test), y_test, average=None)\n",
    "    \n",
    "    #Graph the scores using the graph_Score function if verbose is set to TRUE\n",
    "    if verbose:\n",
    "        graph_Scores((precision_train, precision_test))\n",
    "        \n",
    "        print(f\"Train Avg Precision : {precision_train.mean():.4f}\")\n",
    "        print(f\"Test Avg Precision : {precision_test.mean():.4f}\")\n",
    "        \n",
    "    return precision_train, precision_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5867334",
   "metadata": {},
   "source": [
    "## Feature Set up & Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bc5ef",
   "metadata": {},
   "source": [
    "### Music Dataset\n",
    "We will use the music dataset as out dataset. Each instance represents distinct features with the song:\n",
    "- `Artist Name`       - Name of artist\n",
    "- `Track Name`        - Name of song\n",
    "- `Popularity`        - a value between 0 and 100, with 100 being the most popular\n",
    "- `danceability`      - describes how suitable a track is for dancing\n",
    "- `energy`            - perceptual measure of intensity and activity\n",
    "- `key`               - The key the track is in\n",
    "- `loudness`          - The overall loudness of a track in decibels (dB)\n",
    "- `mode`              - indicates the modality (major or minor) of a track\n",
    "- `speechiness`       - detects the presence of spoken words in a track\n",
    "- `acousticness`      - A measure for whether the track is acoustic\n",
    "- `instrumentalness`  - Predicts whether a track contains no vocals\n",
    "- `liveness`          - Detects the presence of an audience in the recording\n",
    "- `valence`           - Describes the musical positiveness conveyed by a track\n",
    "- `tempo`             - The overall estimated tempo of a track in beats per minute (BPM)\n",
    "- `duration_inmin/ms` - Duration in ms\n",
    "- `time_signature`    - Specifies how many beats are in each bar (or measure)\n",
    "\n",
    "The songs can be divided into 11 different genres. Upon searching the different songs of the same classes in Google, I as able to determine the 11 classes.\n",
    "- `Pop`        - class 0\n",
    "- `Hip-hop`    - class 1\n",
    "- `Blues`      - class 2\n",
    "- `Indian-pop` - class 3\n",
    "- `Country`    - class 4\n",
    "- `Rap`        - class 5\n",
    "- `Rock`       - class 6\n",
    "- `Ambient`    - class 7\n",
    "- `Metal`      - class 8\n",
    "- `R&B`        - class 9\n",
    "- `Indie`      - class 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e55c1",
   "metadata": {},
   "source": [
    "### Loading & Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a7e008",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m         X_music \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([X_music, features])\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# Append the class label\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m         y_music \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(y_music, np\u001b[38;5;241m.\u001b[39marray([classes[row[\u001b[38;5;241m16\u001b[39m]]]))  \u001b[38;5;66;03m# Class column\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Reshape y_music to have the shape (N, 1)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m y_music \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(y_music, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '5'"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    'Pop': 0,\n",
    "    'Hip-hop': 1,\n",
    "    'Blues': 2,\n",
    "    'Indian-pop': 3,\n",
    "    'Country': 4,\n",
    "    'Rap': 5,\n",
    "    'Rock': 6,\n",
    "    'Ambient': 7,\n",
    "    'Metal': 8,\n",
    "    'R&B': 9,\n",
    "    'Indie': 10,\n",
    "}\n",
    "X_music = []\n",
    "y_music = []\n",
    "\n",
    "with open('Dataset 6 - Music Dataset/music.csv', 'r') as csv_file:\n",
    "    raw_data = csv.reader(csv_file)\n",
    "    X_music = np.empty((0, 13), float)  # 13 numeric feature columns\n",
    "    y_music = np.empty((0, 1), int)\n",
    "    \n",
    "    next(raw_data)  # Skip the header row\n",
    "    \n",
    "    for row in raw_data:\n",
    "        # Convert the relevant columns to float and add to X_music\n",
    "        features = np.array([float(row[2]),  # Popularity\n",
    "                             float(row[3]),  # danceability\n",
    "                             float(row[4]),  # energy\n",
    "                             float(row[5]),  # key\n",
    "                             float(row[6]),  # loudness\n",
    "                             float(row[7]),  # mode\n",
    "                             float(row[8]),  # speechiness\n",
    "                             float(row[9]),  # acousticness\n",
    "                             float(row[11]), # liveness\n",
    "                             float(row[12]), # valence\n",
    "                             float(row[13]), # tempo\n",
    "                             float(row[14]), # duration_inmin/ms\n",
    "                             float(row[15])  # time_signature\n",
    "                            ])\n",
    "        X_music = np.vstack([X_music, features])\n",
    "        \n",
    "        # Append the class label\n",
    "        y_music = np.append(y_music, np.array([classes[row[16]]]))  # Class column\n",
    "    \n",
    "# Reshape y_music to have the shape (N, 1)\n",
    "y_music = np.expand_dims(y_music, 1)\n",
    "\n",
    "print('Training data shape:', X_music.shape)\n",
    "print('Ground truth values shape:', y_music.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b30d9",
   "metadata": {},
   "source": [
    "We will make the results reproducible by assigning the random_state with a random arbitrary value of 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9ac243",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbca50",
   "metadata": {},
   "source": [
    "Get the number of instances for each feature of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc3f820",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 13 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_music_0 \u001b[38;5;241m=\u001b[39m X_music[y_music \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m X_music_1 \u001b[38;5;241m=\u001b[39m X_music[y_music \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m X_music_2 \u001b[38;5;241m=\u001b[39m X_music[y_music \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 13 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "X_music_0 = X_music[y_music == 0]\n",
    "X_music_1 = X_music[y_music == 1]\n",
    "X_music_2 = X_music[y_music == 2]\n",
    "X_music_3 = X_music[y_music == 3]\n",
    "X_music_4 = X_music[y_music == 4]\n",
    "X_music_5 = X_music[y_music == 5]\n",
    "X_music_6 = X_music[y_music == 6]\n",
    "X_music_7 = X_music[y_music == 7]\n",
    "X_music_8 = X_music[y_music == 8]\n",
    "X_music_9 = X_music[y_music == 9]\n",
    "X_music_10 = X_music[y_music == 10]\n",
    "\n",
    "print('Number of class 0:', len(X_music_0))\n",
    "print('Number of class 1:', len(X_music_1))\n",
    "print('Number of class 2:', len(X_music_2))\n",
    "print('Number of class 3:', len(X_music_3))\n",
    "print('Number of class 4:', len(X_music_4))\n",
    "print('Number of class 5:', len(X_music_5))\n",
    "print('Number of class 6:', len(X_music_6))\n",
    "print('Number of class 7:', len(X_music_7))\n",
    "print('Number of class 8:', len(X_music_8))\n",
    "print('Number of class 9:', len(X_music_9))\n",
    "print('Number of class 10:', len(X_music_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7285fff",
   "metadata": {},
   "source": [
    "Divide the dataset into the train and test set. The test set will contain X instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd996b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)\n",
    "\n",
    "#Print the shapes of each set\n",
    "print(f'X_train {X_train.shape}')\n",
    "print(f'y_train {y_train.shape}')\n",
    "print(f'X_test {X_test.shape}')\n",
    "print(f'y_test {y_test.shape}')\n",
    "\n",
    "#Create the bars for the histogram\n",
    "plt.hist(y_train, bins=np.arange(0.5, 11.5, 1), rwidth = 0.5, label='Train', edgecolor='black')\n",
    "plt.hist(y_test, bins=np.arange(0.5, 11.5, 1), rwidth = 0.5, label='Test', edgecolor='black')\n",
    "\n",
    "#Show integers in the x axis accordingly\n",
    "plt.xticks(np.arange(0, 11, 1))\n",
    "\n",
    "#Labels\n",
    "plt.ylabel('Samples Taken')\n",
    "plt.xlabel('Class / Genre')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52df5ca",
   "metadata": {},
   "source": [
    "Convert the np.ndarray arrays to torch.Tensor. We use torch.Tensor in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ed87f",
   "metadata": {},
   "source": [
    "# 3.1 Neural Network\n",
    "\n",
    "Instantiation of the Neural Network with the following parameters:\n",
    "- `Input` - 13\n",
    "- `Output` - 11\n",
    "- `Hidden layers` - 2\n",
    "- `list_hidden` - (20,10)\n",
    "- `activation` - sigmoid\n",
    "- `Verbose` - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(13, 11, list_hidden=(20, 10))\n",
    "network.create_network()\n",
    "network.init_weights()\n",
    "network.forward(X_train, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179779f4",
   "metadata": {},
   "source": [
    "Well use Adam as the optimizer with the following parameters:\n",
    "- `params` - the parameters of the network\n",
    "- `lr` = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), 0.001)\n",
    "target_classes = torch.Tensor(y_train[random_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d5eff",
   "metadata": {},
   "source": [
    "Then instantiated a nn.CrossEntropyLoss() object to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(scores, target_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916f305",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "We will be using the dataset titled: `Dataset 6 - Music Dataset` for our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader('Dataset 6 - Music Dataset/music.csv', True, True).df['standardize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86980079",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 100\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    X_batch, y_batch = data_loader.get_batch(mode='train')\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scores, probabilities = network.forward(X)\n",
    "        \n",
    "        loss = criterion(scores, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00000005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6acf5",
   "metadata": {},
   "source": [
    "Visualizing the lost per training epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(len(losses))]\n",
    "y_values = losses\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for each training epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885a23c",
   "metadata": {},
   "source": [
    "### Trying out the trained network on the test data\n",
    "Setting it to eval mode first to avoid updating the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61065c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299c9d4",
   "metadata": {},
   "source": [
    "Then perform forwad propagation on the test data and get the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d49c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,probalities = network.forward(X_test);\n",
    "predictions = network.predict(X_test)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93b915",
   "metadata": {},
   "source": [
    "Get the accuracy of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = torch.sum(predictions == y_test)\n",
    "accuracy = num_correct/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe72fd-9140-4ec7-ac1e-678eb4cda33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ver of the dataframe you want to use\n",
    "# df = DataLoader('Dataset 6 - Music Dataset/music.csv', True, True).df['raw']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
